## Topic: Troubleshoot Cluster Components

### 1. Theory
Troubleshooting cluster components involves diagnosing and resolving issues in the **control plane** (API server, controller manager, scheduler, etcd) and **worker node components** (kubelet, kube-proxy, container runtime). These components are the backbone of a Kubernetes cluster, and failures can disrupt cluster operations, from pod scheduling to network connectivity.

- **Control Plane Components**:
  - Manage cluster state and orchestrate resources.
  - Run as static pods (on master nodes) or in the `kube-system` namespace (managed clusters).
  - Issues here cause cluster-wide failures (e.g., API downtime, unschedulable pods).

- **Worker Node Components**:
  - Execute workloads and manage node-level networking and containers.
  - Failures lead to node-specific issues (e.g., pods stuck in `Pending`, service outages).
  - Require node-level debugging (logs, runtime tools).

**Why It Matters for CKA**:
- The CKA exam tests your ability to troubleshoot critical components under time pressure, often requiring log analysis, manifest edits, or runtime debugging.
- Tasks simulate real-world scenarios, like fixing a crashed API server or a misconfigured kubelet, demanding fluency with `kubectl` and Linux tools.

**Big Picture**:
- Control plane components are interdependent (e.g., API server relies on etcd), so issues cascade.
- Worker node components interact with the control plane, and failures isolate nodes or disrupt workloads.
- Troubleshooting combines high-level inspection (`kubectl`) with low-level diagnostics (logs, `crictl`).

---

### 2. Key Concepts and Components
#### Control Plane Components
- **API Server**:
  - **Role**: Cluster gateway, handles all API requests (e.g., `kubectl`, kubelet).
  - **Common Issues**:
    - Authentication errors (e.g., invalid tokens).
    - TLS issues (e.g., expired certificates).
    - Connectivity failures (e.g., etcd unreachable).
  - **Diagnostics**:
    - Logs: `kubectl logs kube-apiserver-<node> -n kube-system` or `/var/log/kube-apiserver.log`.
    - Manifest: `/etc/kubernetes/manifests/kube-apiserver.yaml` (static pod).
  - **Configuration**:
    - Flags: `--etcd-servers`, `--service-account-key-file`, `--tls-cert-file`.
    - Ports: 6443 (secure), 8080 (insecure, if enabled).

- **Controller Manager**:
  - **Role**: Runs controllers (e.g., ReplicaSet, Deployment, Node) to reconcile desired state.
  - **Common Issues**:
    - Stuck controllers (e.g., pods not scaling).
    - Leader election failures (multiple instances fighting).
    - Resource limits causing crashes.
  - **Diagnostics**:
    - Logs: `kubectl logs kube-controller-manager-<node> -n kube-system`.
    - Manifest: `/etc/kubernetes/manifests/kube-controller-manager.yaml`.
  - **Configuration**:
    - Flags: `--leader-elect`, `--controllers`.

- **Scheduler**:
  - **Role**: Assigns pods to nodes based on predicates (e.g., resource availability) and priorities (e.g., affinity).
  - **Common Issues**:
    - Unschedulable pods (e.g., taints, resource shortages).
    - Scheduler crash or misconfiguration.
  - **Diagnostics**:
    - Logs: `kubectl logs kube-scheduler-<node> -n kube-system`.
    - Pod events: `kubectl describe pod`.
    - Manifest: `/etc/kubernetes/manifests/kube-scheduler.yaml`.
  - **Configuration**:
    - Flags: `--policy-config-file`, `--algorithm-provider`.

- **etcd**:
  - **Role**: Distributed key-value store for cluster state.
  - **Common Issues**:
    - Quorum loss (e.g., <50% members available).
    - Disk latency (slow I/O).
    - Certificate errors (e.g., expired client certs).
  - **Diagnostics**:
    - Health: `etcdctl cluster-health`, `etcdctl member list`.
    - Logs: `kubectl logs etcd-<node> -n kube-system`.
    - Manifest: `/etc/kubernetes/manifests/etcd.yaml`.
  - **Tools**:
    - `etcdctl`: CLI for etcd operations (requires certs).

#### Worker Node Components
- **Kubelet**:
  - **Role**: Manages pods and containers, reports node status to API server.
  - **Common Issues**:
    - Crashes (e.g., OOM, cert errors).
    - Misconfigurations (e.g., wrong API server endpoint).
    - Resource pressure preventing pod starts.
  - **Diagnostics**:
    - Logs: `journalctl -u kubelet` or `/var/log/kubelet.log`.
    - Status: `systemctl status kubelet`.
    - Config: `/var/lib/kubelet/config.yaml`, `/etc/kubernetes/kubelet.conf`.
  - **Configuration**:
    - Flags: `--kubeconfig`, `--container-runtime`.

- **Kube-Proxy**:
  - **Role**: Manages network rules for services (iptables or IPVS).
  - **Common Issues**:
    - Service connectivity failures (e.g., no traffic to pods).
    - Crash or misconfiguration (e.g., wrong mode).
  - **Diagnostics**:
    - Logs: `kubectl logs kube-proxy-<node> -n kube-system`.
    - Mode: Check `--proxy-mode` (iptables, IPVS).
    - Rules: `iptables -L` or `ipvsadm -Ln`.
  - **Configuration**:
    - Flags: `--proxy-mode`, `--cluster-cidr`.

- **Container Runtime**:
  - **Role**: Executes containers (e.g., containerd, Docker).
  - **Common Issues**:
    - Runtime crashes (e.g., socket errors).
    - Image pull failures.
    - Container creation errors.
  - **Diagnostics**:
    - Status: `systemctl status containerd`.
    - Containers: `crictl ps`, `crictl logs <container-id>`.
    - Logs: `journalctl -u containerd`.
  - **Tools**:
    - `crictl`: CRI-compatible CLI for containerd.

#### Exam Relevance
- **High Weight**: Component troubleshooting is critical, with tasks like fixing crashed pods or misconfigured runtimes.
- **Practical Focus**: Expect to edit manifests, check logs, and use `crictl`/`etcdctl`.
- **Version Notes**: v1.29+ uses containerd, systemd logs; static pods are standard for control plane.

---

### 3. YAML Examples
Troubleshooting often involves editing existing manifests or creating debug pods. Below are examples for debugging and simulating issues.

#### Example 1: Debug Pod for Component Access
```yaml
# File: troubleshoot/debug-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: debug-pod
  namespace: kube-system
spec:
  containers:
  - name: debug
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
    volumeMounts:
    - name: host-logs
      mountPath: /host-logs
    - name: host-manifests
      mountPath: /host-manifests
  volumes:
  - name: host-logs
    hostPath:
      path: /var/log
  - name: host-manifests
    hostPath:
      path: /etc/kubernetes/manifests
  nodeName: <node-name> # Replace with master/worker node
```

**Critical Fields**:
- `spec.volumes.hostPath`: Mounts logs (`/var/log`) and manifests (`/etc/kubernetes/manifests`).
- `spec.nodeName`: Targets specific node (e.g., master for control plane).
- `spec.containers.command`: Keeps pod running for debugging.

#### Example 2: Simulate Kubelet Failure
```yaml
# File: troubleshoot/bad-kubelet-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: bad-kubelet-pod
  namespace: default
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "10Gi" # Exceeds node capacity
```

**Purpose**: Simulates unschedulable pod to debug kubelet/scheduler.

---

### 4. Critical Commands
Key commands for troubleshooting components:

| Command | Description | Exam Tip |
|---------|-------------|----------|
| `kubectl get pods -n kube-system` | Control plane/kube-proxy pod status. | Check for `CrashLoopBackOff`. |
| `kubectl logs <pod> -n kube-system` | Component logs. | Use `--previous` for crashes. |
| `kubectl describe pod <pod> -n kube-system` | Pod events. | Look for config errors. |
| `journalctl -u kubelet` | Kubelet logs. | Debug node issues. |
| `systemctl status kubelet` | Kubelet service status. | Verify running. |
| `journalctl -u containerd` | Container runtime logs. | Check container failures. |
| `crictl ps` | List running containers. | Debug runtime issues. |
| `crictl logs <container-id>` | Container logs. | Alternative to `kubectl logs`. |
| `etcdctl cluster-health` | etcd health check. | Requires certs. |
| `etcdctl member list` | etcd members. | Verify quorum. |
| `iptables -L` | Check kube-proxy rules (iptables mode). | Debug service issues. |
| `ipvsadm -Ln` | Check kube-proxy rules (IPVS mode). | Verify service routing. |

---

### 5. Step-by-Step Diagnostics
Here’s how to troubleshoot common component issues.

#### Scenario 1: API Server Crash
**Step 1: Check Status**
```bash
kubectl get pods -n kube-system
# Output: NAME                            READY   STATUS             RESTARTS
#         kube-apiserver-master-1         0/1     CrashLoopBackOff   5
```

**Step 2: Inspect Events**
```bash
kubectl describe pod kube-apiserver-master-1 -n kube-system
# Events: "Failed to start: invalid --etcd-servers"
```

**Step 3: Check Logs**
```bash
kubectl logs kube-apiserver-master-1 -n kube-system --previous
# Output: "etcd: connection refused"
```

**Step 4: Debug etcd**
```bash
kubectl get pods -n kube-system | grep etcd
# Output: etcd-master-1   1/1   Running

# Use debug pod
kubectl apply -f troubleshoot/debug-pod.yaml
kubectl exec -it debug-pod -n kube-system -- sh
etcdctl --endpoints=https://127.0.0.1:2379 cluster-health
# Output: "unhealthy: connection refused"

# Fix manifest
vi /host-manifests/kube-apiserver.yaml
# Correct: --etcd-servers=https://127.0.0.1:2379
```

**Step 5: Verify**
```bash
kubectl get pods -n kube-system
# Output: STATUS: Running
```

#### Scenario 2: Kubelet Failure
**Step 1: Check Pods**
```bash
kubectl get pods
# Output: NAME              READY   STATUS    RESTARTS   AGE
#         bad-kubelet-pod   0/1     Pending   0          1m
```

**Step 2: Inspect Pod**
```bash
kubectl describe pod bad-kubelet-pod
# Events: "FailedScheduling: insufficient memory"
```

**Step 3: Check Node**
```bash
kubectl describe node node-1
# Conditions: MemoryPressure=True
```

**Step 4: Check Kubelet**
```bash
kubectl exec -it debug-pod -n kube-system -- sh
journalctl -u kubelet
# Output: "Unable to schedule: low memory"
```

**Step 5: Fix**
```bash
kubectl edit pod bad-kubelet-pod
# Reduce: resources.requests.memory: 500Mi
kubectl describe node node-1
# Confirm: MemoryPressure=False
kubectl get pods
# Output: STATUS: Running
```

---

### 6. Exam-Style Questions
Below are CKA-style questions, with estimated times and answers.

#### Question 1: Task-Based (6 minutes)
**Task**: Fix a crashed scheduler pod by correcting its manifest.

**Steps**:
```bash
kubectl get pods -n kube-system
# Output: kube-scheduler-master-1   0/1   CrashLoopBackOff

kubectl describe pod kube-scheduler-master-1 -n kube-system
# Events: "Invalid --policy-config-file"

kubectl logs kube-scheduler-master-1 -n kube-system --previous
# Output: "No such file"

# Fix manifest
kubectl exec -it debug-pod -n kube-system -- sh
vi /host-manifests/kube-scheduler.yaml
# Remove: --policy-config-file

# Verify
kubectl get pods -n kube-system
# Output: STATUS: Running
```

#### Question 2: Troubleshooting (8 minutes)
**Task**: A kubelet issue causes pods to stay `Pending`. Debug and fix.

**Steps**:
```bash
kubectl get pods
# Output: NAME   READY   STATUS    RESTARTS   AGE
#         app    0/1     Pending   0          1m

kubectl describe pod app
# Events: "FailedScheduling: node not ready"

kubectl get nodes
# Output: node-1   NotReady

kubectl exec -it debug-pod -n kube-system -- sh
systemctl status kubelet
# Output: "inactive (dead)"

journalctl -u kubelet
# Output: "certificate expired"

# Fix (example: rotate certs)
/host-bin/kubeadm certs renew kubelet
systemctl restart kubelet

# Verify
kubectl get nodes
# Output: node-1   Ready
kubectl get pods
# Output: STATUS: Running
```

#### Question 3: Validation (4 minutes)
**Task**: Confirm all control plane components are running and kubelet is functional.

**Steps**:
```bash
kubectl get pods -n kube-system
# Output: All Running (kube-apiserver, etcd, scheduler, controller-manager)

kubectl get nodes
# Output: All Ready

# Test kubelet
kubectl create -f troubleshoot/bad-kubelet-pod.yaml
kubectl get pods
# Output: STATUS: Running or Pending (scheduling works)
```

---

### 7. Important Key Points to Remember
- **Control Plane**:
  - **API Server**: Gateway, fails on etcd/TLS issues.
  - **Controller Manager**: Reconciles state, fails on leader election.
  - **Scheduler**: Assigns pods, fails on taints/resources.
  - **etcd**: Stores state, fails on quorum/disk.
- **Worker Node**:
  - **Kubelet**: Runs pods, fails on certs/resources.
  - **Kube-Proxy**: Manages services, fails on rules/mode.
  - **Container Runtime**: Executes containers, fails on sockets/images.
- **Diagnostics**:
  - `kubectl logs/describe`: Control plane pods.
  - `journalctl`, `systemctl`: Kubelet, runtime.
  - `crictl`: Container runtime.
  - `etcdctl`: etcd health.
- **Configuration**:
  - Static pods: `/etc/kubernetes/manifests`.
  - Kubelet: `/var/lib/kubelet/config.yaml`.
  - Kube-Proxy: `--proxy-mode` (iptables, IPVS).
- **Exam Focus**:
  - Fix crashes via manifests/logs.
  - Debug kubelet/scheduler for `Pending` pods.
  - Validate with `kubectl get`.
- **Version Note**:
  - v1.29+: Containerd, static pods, systemd logs.

---

### 8. Common Mistakes to Avoid
- **Mistake**: Forgetting `-n kube-system` for control plane pods.
  - **Fix**: Always specify namespace.
- **Mistake**: Not checking `--previous` logs for crashes.
  - **Fix**: Use `kubectl logs --previous`.
- **Mistake**: Ignoring etcd for API server issues.
  - **Fix**: Check `etcdctl cluster-health` first.
- **Mistake**: Misconfiguring kubelet without restarting.
  - **Fix**: Run `systemctl restart kubelet`.
- **Mistake**: Assuming kube-proxy mode (iptables vs. IPVS).
  - **Fix**: Check logs or `ipvsadm`.

**Exam Traps**:
- Missing cert paths in `etcdctl` commands.
- Not validating fixes with `kubectl get`.
- Spending too long on logs vs. manifests.

---

### 9. Troubleshooting Tips
- **API Server Failure**:
  - Check: `kubectl describe pod`, logs.
  - Causes: etcd down, TLS errors, flags.
  - Fix: Correct manifest, restart kubelet.
- **Kubelet Crash**:
  - Check: `systemctl status kubelet`, `journalctl`.
  - Causes: Certs, config, resources.
  - Fix: Renew certs, edit config, restart.
- **Scheduler Issues**:
  - Check: `kubectl describe pod`, scheduler logs.
  - Causes: Taints, resources, config.
  - Fix: Remove taints, adjust resources.
- **etcd Problems**:
  - Check: `etcdctl cluster-health`, logs.
  - Causes: Quorum, disk, certs.
  - Fix: Restore quorum, check I/O.
- **Tools**:
  - `kubectl describe/logs`: Pod issues.
  - `crictl`: Runtime debugging.
  - `journalctl`: Node services.
  - `etcdctl`: etcd status.

**Debugging Checklist**:
1. Check component status (`kubectl get pods -n kube-system`).
2. Review events (`kubectl describe`).
3. Fetch logs (`kubectl logs`, `journalctl`).
4. Inspect configs (`/etc/kubernetes`).
5. Validate fixes (`kubectl get`).

---

### 10. Additional Resources
- **Kubernetes Docs**:
  - [Debug Cluster](https://kubernetes.io/docs/tasks/debug/debug-cluster/)
  - [Control Plane](https://kubernetes.io/docs/concepts/overview/components/)
  - [etcd](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)
- **Practice Tools**:
  - **Minikube**: Simulate component failures.
  - **KillerCoda/KodeKloud**: CKA labs.
  - **Kind**: Multi-node clusters.
- **Community**:
  - CNCF Slack: #kubernetes-users, #cka-prep.
  - Kubernetes GitHub: Issues for components.
  - X posts: Search #KubernetesTroubleshooting, #CKA.

---

### 11. GitHub Repo Integration
Here’s how to organize this topic in your GitHub repo.

#### Folder Structure
```
cka-prep/
├── storage/
├── troubleshoot/
│   ├── debug-pod.yaml
│   ├── bad-kubelet-pod.yaml
│   ├── README.md
├── README.md
```

#### README Content (troubleshoot/README.md, Updated)
```markdown
# Troubleshoot: Troubleshoot Cluster Components

## Theory
- **Control Plane**: API server, controller manager, scheduler, etcd.
- **Worker Node**: Kubelet, kube-proxy, container runtime.
- Issues: Crashes, configs, connectivity.

## YAML Examples
- `debug-pod.yaml`: Access logs/manifests.
- `bad-kubelet-pod.yaml`: Simulate kubelet failure.

## Diagnostics
1. Check pods: `kubectl get pods -n kube-system`
2. Events: `kubectl describe pod`
3. Logs: `kubectl logs`, `journalctl -u kubelet`
4. Runtime: `crictl ps`
5. etcd: `etcdctl cluster-health`
6. Fix: Edit manifests, restart services.

## Key Points
- API server needs etcd.
- Kubelet fails on certs/resources.
- Scheduler logs show unschedulable pods.

## Common Mistakes
- Missing `-n kube-system`.
- Ignoring `--previous` logs.
- Not restarting kubelet.

## Troubleshooting
- API crash? Check etcd, manifests.
- Pods `Pending`? Debug kubelet, scheduler.

## Questions
1. Fix scheduler crash.
2. Debug kubelet for `Pending` pods.
3. Verify component health.
```

#### File Comments (bad-kubelet-pod.yaml)
```yaml
# bad-kubelet-pod.yaml
# Simulates pod that fails to schedule (high resources)
# Verify: kubectl describe pod bad-kubelet-pod
# Use: Debug kubelet/scheduler issues
```

---

### Comprehensive Summary
This topic builds on cluster troubleshooting by diving into specific components, from the API server to the container runtime. You’ve learned:
- How to diagnose and fix control plane issues (e.g., etcd quorum, scheduler crashes).
- How to debug worker node components (e.g., kubelet certs, kube-proxy rules).
- Practical skills like editing manifests, using `crictl`, and checking `etcdctl`.

**Practice Plan**:
- Deploy `bad-kubelet-pod.yaml` to simulate failures (Minikube, Kind).
- Break components (e.g., edit manifest flags, stop containerd) and fix.
- Use `debug-pod.yaml` to practice log/config access.
- Time yourself on the exam questions (<20 minutes total).

**Next Steps**:
- Move to the next troubleshooting topic (e.g., “Troubleshoot Application Failures”).
- Practice mixed scenarios (e.g., API server + kubelet issues).
- Let me know if you want more failure simulations or specific tools (e.g., `etcdctl`).

---

This response covers **Troubleshoot Cluster Components** comprehensively, tailored for your CKA prep and GitHub repo. Thanks for keeping me on track—loving the progress! Please share the next topic, and I’ll keep the deep dives coming. Any tweaks or focus areas (e.g., more runtime debugging)? Let’s keep rocking this prep! 😊
